{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4V+lz3rHtEi4nb/wSIrHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roseco-crs/bstat/blob/main/Neural_Network_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of Neural Network from scratch"
      ],
      "metadata": {
        "id": "s_qZHoWZUyO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Pytorch library\n",
        "import torch"
      ],
      "metadata": {
        "id": "zQK_9mbfU6dL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input \n",
        "X = torch.Tensor([[1,0,1,0], [1,0,1,1], [0,1,0,1]])\n",
        "# Output\n",
        "y = torch.Tensor([[1], [1], [0]])\n",
        "print(f\"Input: \\n{X} \\nOutput: \\n{y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHcOr_t0VPmK",
        "outputId": "1cbe449a-f1d3-43c5-98cd-04af74d34dab"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            "tensor([[1., 0., 1., 0.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [0., 1., 0., 1.]]) \n",
            "Output: \n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of activation function.\n",
        "We will use sigmoid function for forward propagation and derivative of sigmoid for backward propagation"
      ],
      "metadata": {
        "id": "Ow-gH0cQWx1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(t):\n",
        "  return 1/(1+torch.exp(-t))\n",
        "\n",
        "def derivative_sigmoid(t):\n",
        "  sig = sigmoid(t)\n",
        "  return sig*(1-sig)\n",
        "  "
      ],
      "metadata": {
        "id": "T6bKc8l7Vuyb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network model architecture:\n",
        "\n",
        "Initialization of \n",
        "\n",
        "1) parameters of the model \n",
        "\n",
        "2) hyperparameters such as epoch and learning rate"
      ],
      "metadata": {
        "id": "ixh3xopZYPFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Neural Network model architecture : \n",
        "    1) input\n",
        "    2) a single hidden layer\n",
        "    3) output\n",
        "\"\"\"\n",
        "\n",
        "inputlayer_neurons = X.shape[1]    # number of features in data  X. In our case it is 4\n",
        "hiddenlayer_neurons = 5            # number of hidden layer. We choose 5\n",
        "output_neurons = y.shape[1]        # number of output. In our case it is 1\n",
        "\n",
        "print(f\"X shape: {X.shape} \\ny shape: {y.shape} \\nFeatures in data X: {X.shape[1]} \\nFeatures in output: {y.shape[1]}\")\n",
        "\n",
        "# Weights and Bias initialization\n",
        "input_hidden_weight = torch.randn(inputlayer_neurons, hiddenlayer_neurons).type(torch.FloatTensor)\n",
        "input_hidden_bias = torch.randn(1, hiddenlayer_neurons).type(torch.FloatTensor)\n",
        "hidden_output_weight = torch.randn(hiddenlayer_neurons, output_neurons)\n",
        "hidden_output_bias = torch.randn(1, output_neurons)\n",
        "\n",
        "# hyperparameters\n",
        "epoch = 5000                        # Training iterations\n",
        "lr = 0.3                            # Learning rate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erkB2Tuybik8",
        "outputId": "4688e124-0695-4152-fac9-11620a15153d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([3, 4]) \n",
            "y shape: torch.Size([3, 1]) \n",
            "Features in data X: 4 \n",
            "Features in output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the model\n"
      ],
      "metadata": {
        "id": "QfRebGK7mSVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epoch):\n",
        "  #Forward Propagation\n",
        "  hidden_layer_input1 = torch.mm(X, input_hidden_weight)\n",
        "  hidden_layer_input = hidden_layer_input1 + input_hidden_bias\n",
        "  hidden_layer_activation = sigmoid(hidden_layer_input)\n",
        "  \n",
        "  output_layer_input1 = torch.mm(hidden_layer_activation, hidden_output_weight)\n",
        "  output_layer_input = output_layer_input1 + hidden_output_bias\n",
        "  output = sigmoid(output_layer_input)\n",
        "  \n",
        "  #Backward Propagation\n",
        "  error = y-output\n",
        "  slope_output_layer = derivative_sigmoid(output)\n",
        "  slope_hidden_layer = derivative_sigmoid(hidden_layer_activation)\n",
        "  d_output = error * slope_output_layer\n",
        "  error_at_hidden_layer = torch.mm(d_output, hidden_output_weight.t())\n",
        "  d_hiddenlayer = error_at_hidden_layer * slope_hidden_layer\n",
        "\n",
        "\n",
        "  hidden_output_weight += torch.mm(hidden_layer_activation.t(), d_output)*lr\n",
        "  hidden_output_bias += d_output.sum()*lr\n",
        "  input_hidden_weight += torch.mm(X.t(), d_hiddenlayer)*lr\n",
        "  input_hidden_bias += d_output.sum()*lr\n",
        "  "
      ],
      "metadata": {
        "id": "XZBkwkUJXiTz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the forward propagation we calculate the output.\n",
        "\n",
        "In the backward propagation we calculate the error and update the weights and biases using this error.\n",
        "\n",
        "Let's see the output from the model."
      ],
      "metadata": {
        "id": "A8irs_1VsPv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Acutal :\\n{y},\\nPredicted :\\n{output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noLuwKX-YmEF",
        "outputId": "82adeeed-2e17-4fde-923f-2c014e776e16"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acutal :\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [0.]]),\n",
            "Predicted :\n",
            "tensor([[0.9993],\n",
            "        [0.9991],\n",
            "        [0.0013]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The target is 1,1,0 and the predicted values from our model are 0.9993, 0.9991, 0.0013. Not bad at all!\n",
        "\n",
        "This is how we can build and train a neural network from strach in Pytorch."
      ],
      "metadata": {
        "id": "2I8AU6nfu3tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K0U-bIpStP9-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}